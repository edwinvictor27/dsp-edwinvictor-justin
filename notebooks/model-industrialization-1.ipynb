{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d392c71-4f5b-411f-a852-e7c3464a9900",
   "metadata": {},
   "source": [
    "# **Installing Pre-requisites for our Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5aa9bf0c-052a-4e5d-9f7b-613a6f051d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from pandas) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from scikit-learn) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pyarrow in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (from pyarrow) (2.0.0)\n",
      "Requirement already satisfied: joblib in d:\\miniconda\\miniconda\\envs\\ml\\lib\\site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install pyarrow\n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8986c1be-e617-418d-860c-60a18b195435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9351599-8e89-49ae-a8c5-a78c1e166347",
   "metadata": {},
   "source": [
    "# **MODEL BUILDING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a842db1b-1e48-4846-b25e-b9659b6a7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file using read_csv function\n",
    "dataset_for_training = r\"C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/data/train.csv\"\n",
    "Training_dataset = pd.read_csv(dataset_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd2c66e5-fe71-463a-ab17-fdbd97a7c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring feature selection variables outside incase if i want to change the features i can do it just here\n",
    "\n",
    "selected_features = ['LotArea', 'GrLivArea', 'Neighborhood', 'HouseStyle'] # 2 continuos and 2 Categorical features\n",
    "target_feature = ['SalePrice']\n",
    "continuos_datatype_features = ['LotArea', 'GrLivArea']\n",
    "discrete_datatype_features = ['Neighborhood', 'HouseStyle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99ba5222-fddc-48cc-bb8f-0a5ef764b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data: pd.DataFrame) -> dict[str, str]:\n",
    "\n",
    "    \"\"\"\n",
    "    Builds a linear regression model, trains it on the provided data, and evaluates its performance.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The dataset to train and evaluate the model on.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, str]: A dictionary containing the root mean squared log error of the model.\n",
    "    \"\"\"\n",
    "\n",
    "## Training_set\n",
    "    \n",
    "    # 1) splitting the dataset\n",
    "    \n",
    "    X = Training_dataset.drop(target_feature, axis=1)\n",
    "    y = Training_dataset[target_feature]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=50)\n",
    "\n",
    "\n",
    "    # 2) Extracting the features from training set\n",
    "    \n",
    "    Extracted_Selected_Features_For_Training = X_train[selected_features]\n",
    "    Extracted_Target_Attribute = y_train[target_feature]\n",
    "    Training_Features = pd.concat([Extracted_Selected_Features_For_Training,y_train], axis=1)\n",
    "\n",
    "    # 3) Encoding the categorical columns from training set\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output= False)\n",
    "    encoder.fit(Training_Features[discrete_datatype_features])\n",
    "    Training_encoded_categories = encoder.transform(Training_Features[discrete_datatype_features])\n",
    "    encoded_discrete_features_training_df = pd.DataFrame(Training_encoded_categories, columns=encoder.get_feature_names_out(discrete_datatype_features))\n",
    "\n",
    "    # 4) Scaling the continuos columns from training set\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[continuos_datatype_features])\n",
    "    scaled_continuos_features_training_df = scaler.transform(X_train[continuos_datatype_features])\n",
    "\n",
    "    # 5) Concatenating the processed training set\n",
    "    \n",
    "    training_continuous_features_df = pd.DataFrame(scaled_continuos_features_training_df , columns= continuos_datatype_features)\n",
    "    Processed_Training_Df = pd.concat([training_continuous_features_df, encoded_discrete_features_training_df] , axis=1)\n",
    "\n",
    "    # 6) Fitting the model\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(Processed_Training_Df, y_train)\n",
    "\n",
    "    #7) SAVING THE MODEL\n",
    "    joblib.dump(model,r'C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/models/model.joblib')\n",
    "    joblib.dump(scaler,r'C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/models/scaler.joblib')\n",
    "    joblib.dump(encoder,r'C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/models/encoder.joblib')\n",
    "\n",
    "## Testing_set   \n",
    "\n",
    "    # 1) Extracting the features from testing set\n",
    "    \n",
    "    Extracted_Features_Testing = X_test[selected_features]\n",
    "    Testing_Features = pd.concat([Extracted_Features_Testing,y_test], axis=1)\n",
    "\n",
    "    # 2) Encoding the categorical columns from testing set\n",
    "    \n",
    "    encoder.fit(Testing_Features[discrete_datatype_features])\n",
    "    Testing_encoded_categories = encoder.transform(Testing_Features[discrete_datatype_features])\n",
    "    encoded_discrete_features_testing_df = pd.DataFrame(Testing_encoded_categories, columns=encoder.get_feature_names_out(discrete_datatype_features))\n",
    "\n",
    "    # 3) Scaling the continuos columns from testing set\n",
    "    \n",
    "    scaler.fit(X_test[continuos_datatype_features])\n",
    "    scaled_continuos_features_testing_df = scaler.transform(X_test[continuos_datatype_features])\n",
    "\n",
    "    # 4) Concatenating the processed testing set\n",
    "    \n",
    "    testing_continuous_features_df = pd.DataFrame(scaled_continuos_features_testing_df , columns= continuos_datatype_features)\n",
    "    Processed_Testing_Df = pd.concat([testing_continuous_features_df, encoded_discrete_features_testing_df] , axis=1)\n",
    "    \n",
    "    # 5) Making prediction \n",
    "    \n",
    "    y_pred = model.predict(Processed_Testing_Df)\n",
    "\n",
    "    # 6) Evaluating the model\n",
    "    \n",
    "    Rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred)) \n",
    "    return {'Root Mean Squared Error out of': str(Rmsle) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87b2e349-dac1-4804-9a14-90bcce4bd05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Root Mean Squared Error out of': '0.19357831076666'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(Training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d01444-eca5-402b-bd8a-aaa36bfb829c",
   "metadata": {},
   "source": [
    "# **MODEL INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d4efbcd-e6ad-4394-b860-bbbcea741831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(input_data: pd.DataFrame) -> np.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "    Makes predictions on house prices based on the provided input data using\n",
    "    pre-trained model, scaler, and encoder.\n",
    "\n",
    "    Args:\n",
    "        input_data (pd.DataFrame): DataFrame containing the test data.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of predicted house prices.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_for_testing = r\"C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/data/test.csv\"\n",
    "    scaler_location = r'C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/models/scaler.joblib'\n",
    "    encoder_location = r'C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/models/encoder.joblib'\n",
    "    model_location = r'C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/models/model.joblib'\n",
    "\n",
    "    model = joblib.load(model_location)\n",
    "    scaler = joblib.load(scaler_location)\n",
    "    encoder = joblib.load(encoder_location)\n",
    "\n",
    "    continuos_datatype_features = ['LotArea', 'GrLivArea']\n",
    "    discrete_datatype_features = ['Neighborhood', 'HouseStyle']\n",
    "\n",
    "    test_scaled = scaler.transform(Testing_df[continuos_datatype_features])\n",
    "    test_encoded = encoder.transform(Testing_df[discrete_datatype_features])\n",
    "\n",
    "    selected_features = ['LotArea', 'GrLivArea', 'Neighborhood', 'HouseStyle'] # 2 continuos and 2 Categorical features\n",
    "    target_feature = ['SalePrice']\n",
    "   \n",
    "    \n",
    "    test_scaled_df = pd.DataFrame(test_scaled,columns=continuos_datatype_features)\n",
    "    test_encoded_df = pd.DataFrame(test_encoded,columns=encoder.get_feature_names_out(discrete_datatype_features))\n",
    "    \n",
    "    Transformed_test_df = pd.concat([test_scaled_df,test_encoded_df], axis=1)\n",
    "\n",
    "    predict_house_price = model.predict(Transformed_test_df)\n",
    "    return predict_house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ca3db35-912a-4c1f-99b6-fe9ee6287402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111539.65323364]\n",
      " [153677.46598706]\n",
      " [185488.24754898]\n",
      " ...\n",
      " [157965.97784075]\n",
      " [144389.60544552]\n",
      " [197115.00156427]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "dataset_for_testing = r\"C:/Users/edwin victor/git repositories/dsp-edwinvictor-justin/data/test.csv\"\n",
    "Testing_df = pd.read_csv(dataset_for_testing)\n",
    "predictions = make_predictions(Testing_df)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940a24e-08a3-4601-9005-a78f5373fead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c1196-45f7-4e21-997f-0cb6ca6deb79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
